{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm as Norm\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path):\n",
    "    return np.array([cv2.imread(join(path, file), cv2.IMREAD_COLOR) for file in sorted(listdir(path))])\n",
    "\n",
    "def center_crop(img, ratio=0.1):\n",
    "    h, w = img.shape[:-1]\n",
    "    h, w = int(h*ratio), int(w*ratio)\n",
    "    return img[h:-h, w:-w]\n",
    "\n",
    "def indices_sampling(images, size=50):\n",
    "    # return a random-sampling indices (in 1-d representation)\n",
    "    \n",
    "    # avoid sampling edge points\n",
    "    #img = cv2.GaussianBlur(images[len(images)//2], (3, 3), 0)\n",
    "    canny = cv2.Canny(cv2.cvtColor(images[len(images)//2], cv2.COLOR_BGR2GRAY), 10, 30)\n",
    "    edge_idx = np.ravel_multi_index(np.argwhere(canny > 128).T, canny.shape)\n",
    "\n",
    "    # sampling points with much larger standard deviation\n",
    "    tmp = images.mean(axis=-1).reshape(images.shape[0], -1)\n",
    "    tmp[:, edge_idx] = 0\n",
    "    N, P = tmp.shape\n",
    "    return np.random.choice(tmp.std(axis=0).argsort()[::-1][10:-10], size, replace=False)\n",
    "\n",
    "def get_windows(segment=[20, 40, 60, 70, 80, 85, 90, 92, 94, 96, 98, 100], plot=False, save=False):\n",
    "    # check if len(segment) >= 2, and if segment is in ascending order\n",
    "    idx = np.linspace(0, 127, len(segment), dtype=int)\n",
    "    concate = np.concatenate([np.linspace(segment[i], segment[i+1], idx[i+1]-idx[i]+1)[:-1] for i in range(len(segment)-1)])\n",
    "    ret = np.r_[concate, [segment[-1]]*2, concate[::-1]]\n",
    "    if plot:\n",
    "        plt.plot(np.arange(256), ret)\n",
    "    if save:\n",
    "        plt.savefig('windows.png', dpi=300)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtb_alignment(img1, img2, t=10, M=50, r=1, num_iter=4):\n",
    "    H, W = img1.shape[:-1]\n",
    "    \n",
    "    global_best_d = np.zeros(2)\n",
    "    for i in range(num_iter-1, -1, -1):\n",
    "        scaled_img1 = img1.copy() if i == 0 else cv2.resize(img1, (int(H/(2**i)), int(W/(2**i))), interpolation=cv2.INTER_CUBIC)\n",
    "        scaled_img2 = img2.copy() if i == 0 else cv2.resize(img2, (int(H/(2**i)), int(W/(2**i))), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        h, w = scaled_img1.shape[:-1]\n",
    "        \n",
    "        imgs = np.r_[[scaled_img1, scaled_img2]]\n",
    "        grays = np.average(imgs, axis=-1, weights=[19, 183, 54]).reshape(2, -1)\n",
    "        \n",
    "        med = np.percentile(grays, M, axis=-1).reshape(-1, 1)\n",
    "        low = np.percentile(grays, M-t, axis=-1).reshape(-1, 1)\n",
    "        high = np.percentile(grays, M+t, axis=-1).reshape(-1, 1)\n",
    "        \n",
    "        pad_r = 2*(num_iter-i-1) + r\n",
    "        mtb1, mtb2 = np.pad((grays > med).reshape(2, h, w), ((0, 0), (pad_r, pad_r), (pad_r, pad_r)))\n",
    "        mask1, mask2 = np.pad(((grays > high) + (grays < low)).reshape(2, h, w), ((0, 0), (pad_r, pad_r), (pad_r, pad_r)))\n",
    "\n",
    "        # enumerate all 9 offsets\n",
    "        min_err, best_dir = np.infty, [0, 0]\n",
    "        dir_space = np.mgrid[-r:r+1, -r:r+1].T.reshape(-1, 2)\n",
    "        for j, d in enumerate(dir_space):\n",
    "            print('Scaling %d/%d, searching %02d/%02d' % (num_iter-i, num_iter, j+1, len(dir_space)), end='\\r')\n",
    "            total_d = 2*global_best_d + d\n",
    "            affineM = np.float32(np.r_[[1, 0, 0, 1], total_d]).reshape(3, 2).T\n",
    "            trans_mtb = cv2.warpAffine(np.float32(mtb2), affineM, (w+2*pad_r, h+2*pad_r)).astype(np.int)\n",
    "            trans_mask = cv2.warpAffine(np.float32(mask2), affineM, (w+2*pad_r, h+2*pad_r)).astype(np.int)\n",
    "            err = (((mtb1 ^ trans_mtb) & mask1) & trans_mask).sum()\n",
    "            if err < min_err:\n",
    "                min_err, best_dir = err, total_d\n",
    "        global_best_d = best_dir\n",
    "    print('\\tBest direction:', global_best_d, ' '*10)\n",
    "    return global_best_d\n",
    "\n",
    "def images_alignment(images, shifts=None):\n",
    "    if shifts is None:\n",
    "        shifts = []\n",
    "        for i in range(len(images) - 1):\n",
    "            print('Processing image %d ...' % (i))\n",
    "            # While exposure is too low, set the threshold to 87%, instead of 50% (Median)\n",
    "            M = 87 if i <= 1 else 50\n",
    "            shifts.append(mtb_alignment(images[i], images[i+1], M=M, r=4))\n",
    "            \n",
    "    h, w = images[0].shape[:-1]\n",
    "    global_shift = np.zeros(2)\n",
    "    new_imgs = []\n",
    "    for i, s in enumerate(shifts):\n",
    "        global_shift += s\n",
    "        affineM = np.float32(np.r_[[1, 0, 0, 1], global_shift]).reshape(3, 2).T\n",
    "        new_imgs.append(cv2.warpAffine(images[i+1], affineM, (w, h)))\n",
    "        cv2.imwrite('new_img%02d.JPG' % (i+1), new_imgs[-1])\n",
    "    return shifts, new_imgs\n",
    "\n",
    "def debevec(Z, T, l, w):\n",
    "    N, P = Z.shape\n",
    "    \n",
    "    # fill-in A matrix (by avoiding the for-loop)\n",
    "    A11 = np.zeros((N*P, 256))\n",
    "    A12 = np.zeros((N*P, N))\n",
    "    A_mid = np.zeros(256+N)\n",
    "    A21 = np.zeros((254, 256))\n",
    "    A22 = np.zeros((254, N))\n",
    "    \n",
    "    idx = np.arange(N*P)\n",
    "    Zf = Z.flatten()\n",
    "    A11[idx, Zf] = w[Zf]\n",
    "    A12[idx, np.tile(np.arange(N), (P, 1)).T.flatten()] = -w[Zf]\n",
    "    A_mid[128] = 1\n",
    "    idx = np.arange(254)\n",
    "    A21[idx, idx] = l*w[idx+1]\n",
    "    A21[idx, idx+1] = -2*l*w[idx+1]\n",
    "    A21[idx, idx+2] = l*w[idx+1]\n",
    "    \n",
    "    A = np.r_[np.c_[A11, A12], A_mid.reshape(1, -1), np.c_[A21, A22]]\n",
    "    B = np.r_[w[Zf]*np.tile(T, (1, N)).squeeze(), np.zeros(255)]\n",
    "    \n",
    "    g = np.linalg.pinv(A).dot(B)\n",
    "    return g[:256], g[256:]\n",
    "\n",
    "def another_debevec(Z, T, l, w):\n",
    "    N, P = Z.shape\n",
    "    \n",
    "    A = np.zeros((N*P+257, 256+N))\n",
    "    B = np.zeros((N*P+257, 1))\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(Z.shape[0]):\n",
    "        for j in range(Z.shape[1]):\n",
    "            wij = w[Z[i, j]]\n",
    "            A[k, Z[i, j]] = wij\n",
    "            A[k, 256+i] = -wij\n",
    "            B[k, 0] = wij*T[j]\n",
    "            k += 1\n",
    "    \n",
    "    A[k, 128] = 1\n",
    "    k += 1\n",
    "    for i in range(254):\n",
    "        A[k, i] = l*w[i+1]\n",
    "        A[k, i+1] = -2*l*w[i+1]\n",
    "        A[k, i+2] = l*w[i+1]\n",
    "        k += 1\n",
    "    g = np.linalg.pinv(A).dot(B)\n",
    "    return g[:256], g[256:]\n",
    "\n",
    "def plot_responsive_curves(G, save=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(G[0], np.arange(256), 'b', label='blue')\n",
    "    ax.plot(G[1], np.arange(256), 'g', label='green')\n",
    "    ax.plot(G[2], np.arange(256), 'r', label='red')\n",
    "    ax.set_xlabel('$log X$')\n",
    "    ax.set_ylabel('pixel value')\n",
    "    ax.legend()\n",
    "    if save:\n",
    "        plt.savefig('responsive.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_radiance_map(img, center_ratio=0.1, save=False):\n",
    "    gray = np.log(np.average(img, axis=-1, weights=[19, 183, 54]))\n",
    "    fig, ax = plt.subplots()\n",
    "    m, M = gray.min(), gray.max()\n",
    "    pcm = ax.imshow(gray, norm=Norm(vmin=m, vmax=M, vcenter=m*(1-center_ratio)+M*(center_ratio)), cmap='jet')\n",
    "    ax.set_title('Radiance Map (in log scale)')\n",
    "    fig.colorbar(pcm, ax=ax)\n",
    "    if save:\n",
    "        plt.savefig('radiance.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def hdr_reconstruction(images, T, g, w):\n",
    "    P, H, W = images.shape[:-1]\n",
    "    res = []\n",
    "    # transpose to (3 x h x w x P)\n",
    "    images = images.transpose(3, 1, 2, 0).reshape(3, -1, P)\n",
    "    for i, img in enumerate(images):\n",
    "        e = np.exp(((w[img]*(g[i][img] - np.tile(T, (H*W, 1)))).sum(axis=1))/(w[img].sum(axis=1)))\n",
    "        res.append(e.reshape(H, W))\n",
    "    return np.r_[res].transpose(1, 2, 0)\n",
    "\n",
    "def global_reinhard_tonemapping(hdr, a, white=5, save=False, plot=False):\n",
    "    # white: the percentile of points to be 255 \n",
    "        # e.g. white = [5, 10, 15]: \n",
    "        # 5% points in blue channel would go through 255, \n",
    "        # 10% points in green channel would go through 255, \n",
    "        # 15% points in red channel would go through 255.\n",
    "\n",
    "    h, w = hdr.shape[:-1]\n",
    "    \n",
    "    # transpose to 3 x h x w, and further flatten to 3 x h*w\n",
    "    hdr = hdr.transpose(2, 0, 1).reshape(3, -1)\n",
    "    avg = np.exp((np.log(1e-30+hdr)).mean(axis=-1)).reshape(-1, 1)\n",
    "    mapping = a*hdr/avg\n",
    "    \n",
    "    if isinstance(white, list):\n",
    "        lwhite = np.array([[np.percentile(mapping[i], 100-white[i], axis=-1) for i in range(3)]]).T\n",
    "    else:\n",
    "        lwhite = np.percentile(mapping, 100-white, axis=-1).reshape(-1, 1)\n",
    "        \n",
    "    display = mapping*(1+(mapping/lwhite**2))/(1 + mapping)\n",
    "    display = display.reshape(3, h, w).transpose(1, 2, 0)\n",
    "    display = (display*255).astype(int).clip(0, 255)\n",
    "    if save:\n",
    "        cv2.imwrite('myreinhard.JPG', display)\n",
    "    if plot:\n",
    "        plt.imshow(display[:, :, ::-1])\n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Images path\n",
    "    path = './data/new_images3'\n",
    "\n",
    "    # Shutter Time\n",
    "    # img2_shutter_speed = np.log([32, 16, 8, 4, 2, 1, 1/2, 1/4, 1/8, 1/16, 1/32, 1/64, 1/128, 1/256, 1/512, 1/1024])\n",
    "    img3_shutter_speed = np.log([0.01, 0.02, 0.04, 1/13, 1/6, 1/3, 1, 2, 4, 8])\n",
    "\n",
    "    # BGR Images\n",
    "    images = imread(path)\n",
    "\n",
    "    # Shifts, running the following code segment at the first time.\n",
    "    # shifts, images = images_alignment(images)\n",
    "\n",
    "    # Or, if you've got the shifts between each images, you can also running the following command.\n",
    "    # img3_shifts = np.array([[1, -2], [0, 2], [-2, 1], [0, 0], [-2, 1], [-2, 4], [-1, -4], [2, -7], [3, 8]])\n",
    "    # shifts, images = images_alignment(images, img3_shifts)\n",
    "\n",
    "    images = np.array([center_crop(x, ratio=0.01) for x in images])\n",
    "    blurs = np.array([cv2.GaussianBlur(img, (9, 9), 0) for img in images])\n",
    "    P = len(blurs)\n",
    "\n",
    "    # if save, directly read the result of g function from npy file. Otherwise, running the debevec's algorithm\n",
    "    Save = True\n",
    "    if not Save:\n",
    "        indices = indices_sampling(blurs, size=10000)\n",
    "\n",
    "        # Sampling images' pixel value in a (3 x N x P) form\n",
    "        Z = blurs.transpose(3, 1, 2, 0).reshape(3, -1, P)[:, indices]\n",
    "\n",
    "        G = []\n",
    "        for i in range(3):\n",
    "            g, e = debevec(Z[i], img3_shutter_speed, 5, get_windows())\n",
    "            G.append(g)\n",
    "        with open('g10000.npy', 'wb') as f:\n",
    "            np.save(f, np.r_[G])\n",
    "    else:\n",
    "        with open('g10000.npy', 'rb') as f:\n",
    "            G = np.load(f)\n",
    "    # plot_responsive_curves(G, save=True)\n",
    "\n",
    "    img = hdr_reconstruction(images, img3_shutter_speed, G, get_windows())\n",
    "    \n",
    "    # plot_radiance_map(img, center_ratio=0.6, save=True)\n",
    "\n",
    "    # cv2 implemented tonemapping\n",
    "    para = [1.3, 0, 0.5, 0.1]\n",
    "    tonemapReinhard = cv2.createTonemapReinhard(para[0], para[1], para[2], para[3])\n",
    "    ldr = tonemapReinhard.process(img.astype(np.float32))\n",
    "    ldr[np.isnan(ldr)] = 0\n",
    "    cv2.imwrite('reinhard_%.1f,%.1f,%.1f,%.1f.JPG' % (para[0], para[1], para[2], para[3]), (ldr*255).astype(int))\n",
    "    # convert from BGR to RGB\n",
    "    plt.imshow(ldr[:, :, ::-1])\n",
    "    \n",
    "    # My implementation\n",
    "    # ldr = global_reinhard_tonemapping(img, 0.18, [3, 3, 10], plot=True, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
